'use client';

import {useRef, useState, useCallback, useEffect} from 'react';

export default function useCamera() {
  const videoRef = useRef<HTMLVideoElement>(null);
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);

  const startCamera = useCallback(async () => {
    setIsLoading(true);
    setError(null);

    try {
      const mediaStream = await navigator.mediaDevices.getUserMedia({
        video: { facingMode: 'user', width: 1280, height: 720 },
        audio: false,
      });


      if (videoRef.current) {
        videoRef.current.srcObject = mediaStream;

        videoRef.current.onloadedmetadata = () => {
          videoRef.current?.play().catch(e => {
            console.error('6. –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ video.play():', e);
            setError('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–∏–¥–µ–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞.');
          });
        };
      } else {
        console.warn('4. –≠–ª–µ–º–µ–Ω—Ç <video> (videoRef.current) –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.');
      }


      setStream(mediaStream);

    } catch (err) {
      if (err instanceof Error) {
        if (err.name === 'NotAllowedError') {
          console.error('–û—à–∏–±–∫–∞ getUserMedia:', err.name, '–°–æ–æ–±—â–µ–Ω–∏–µ:', err.message);

          setError('–î–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ –∑–∞–ø—Ä–µ—â–µ–Ω. –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±—Ä–∞—É–∑–µ—Ä–∞.');
        } else if (err.name === 'NotFoundError') {
          setError('–ö–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ –≤–∞—à–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ.');
        } else {
          setError('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ.');
        }
      }
    } finally {
      setIsLoading(false);
    }
  }, [videoRef]);

  useEffect(() => {
    if (videoRef.current && !stream && !isLoading) {
      startCamera();
    }
  }, [videoRef.current, stream, isLoading, startCamera]);

  useEffect(() => {
    if (videoRef.current && stream && !videoRef.current.srcObject) {
      videoRef.current.srcObject = stream;

      videoRef.current.onloadedmetadata = () => {
        videoRef.current?.play().catch(e => {
          console.error('‚Üí –û—à–∏–±–∫–∞ play():', e);
          setError('–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –≤–∏–¥–µ–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫–∞.');
        });
      };
    }
  }, [stream]);

  const stopCamera = useCallback(() => {
    if (stream) {
      stream.getTracks().forEach((track) => track.stop());
      setStream(null);
    }
    if (videoRef.current) {
      videoRef.current.srcObject = null;
    }
  }, [stream]);

  const capturePhoto = useCallback((): string | null => {
    if (!videoRef.current) return null;

    const video = videoRef.current;
    const canvas = document.createElement('canvas');

    const aspectRatio = 1 / 1;

    let width = video.videoWidth;
    let height = video.videoHeight;

    if (width / height > aspectRatio) {
      width = height * aspectRatio;
    } else {
      height = width / aspectRatio;
    }

    canvas.width = width;
    canvas.height = height;

    const context = canvas.getContext('2d');
    if (!context) return null;

    const offsetX = (video.videoWidth - width) / 2;
    const offsetY = (video.videoHeight - height) / 2;

    context.drawImage(
      video,
      offsetX, offsetY, width, height,
      0, 0, width, height
    );

    console.log(`üì∏ –§–æ—Ç–æ –∑–∞—Ö–≤–∞—á–µ–Ω–æ: ${width}x${height} (aspect ratio: ${aspectRatio})`);

    return canvas.toDataURL('image/jpeg', 0.9);
  }, []);

  return {
    videoRef,
    stream,
    error,
    isLoading,
    startCamera,
    stopCamera,
    capturePhoto,
  };
}